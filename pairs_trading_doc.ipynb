{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa0aafc-8e2d-4859-8548-52bd27703165",
   "metadata": {},
   "source": [
    "# Dissertation - Pairs Trading - Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b4ee0-50be-4297-8612-75b04b79df0e",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This notebook serves as a guide, illuminates the practical application of theoretical concepts through code implementation, accompanied by step-by-step explanations. Furthermore, academic references are provided throughout the notebook, enriching the content with insights and facilitating further exploration into the subject. It caters to novices seeking insights into pairs trading strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5babe42-9b2a-44fd-92c1-f695be24685c",
   "metadata": {},
   "source": [
    "## Table of Content:\n",
    "* [1. Set Up of the Backtesting](#set-up)\n",
    "* [2. Distance Approach](#distance-approach)\n",
    "* [3. Cointegration Approach](#cointegration-approach)\n",
    "* [4. Copula Approach](#copula-approach)\n",
    "* [5. Conclusion](#conclusion)\n",
    "* [6. Reference](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65c0c8-c01d-4f39-a161-1764dbde60ef",
   "metadata": {},
   "source": [
    "## 1. Set Up of the Backtesting <a class=\"anchor\" id=\"set-up\"></a>\n",
    "\n",
    "- Data set: data/ftse100_2021_2023_06.csv\n",
    "- Formation start date (date1): 4 January 2021\n",
    "- Formation end date (date2): 30 December 2022\n",
    "- Trading start date (date 3): 1 January 2022\n",
    "- Trading start date (date 4): 30 June 2023\n",
    "- Module used: distance_approach.py, cointegration_approach.py, copula_approach.py, performance_measurement.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94140f8-edcb-47fb-b78c-980d697aaec6",
   "metadata": {},
   "source": [
    "## 2. Distance Approach <a class=\"anchor\" id=\"distance-approach\"></a>\n",
    "\n",
    "This section closely adheres to the methodology suggested by Gatev et al. (2006). The distance approach assesses mispricing using the \"spread,\" indicating the standardized price variance between the pair's two stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8601b19-a427-4f58-89a8-253e6552a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_method(date1, date2, date3, date4, x, df, capital=10000): # formation period: date1, date2. trading period: date3, date4\n",
    "    # formation period\n",
    "    coeff_matrix, coeff_list = forming_pairs(date1, date2, df)\n",
    "    pairs = pair_tickers(coeff_matrix, coeff_list, x)\n",
    "    print(pairs)\n",
    "    # trading period\n",
    "    period_return = []\n",
    "    for i in pairs:\n",
    "        pair1 = i[0]\n",
    "        pair2 = i[1]\n",
    "        df_pair1, df_pair2 = trading_df(pair1, pair2, date1, date2, date3, date4, df)\n",
    "        profit_1 = trading(df_pair1, capital)\n",
    "        profit_2 = trading(df_pair2, capital)\n",
    "        pair_return = pair_profit(profit_1, profit_2)\n",
    "        period_return.append(pair_return)\n",
    "    pairs_and_returns = dict(zip(period_return, pairs)) \n",
    "    return(period_return)\n",
    "    return(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d369bd0-1c59-4d52-a3e4-ecbf39039921",
   "metadata": {},
   "source": [
    "## Formation Period\n",
    "\n",
    "### 1. Normalization of the input data in formation period\n",
    "\n",
    "The normalized price denotes the cumulative return sequence, computed by dividing the closing prices by the closing price on the initial day of the formation period, then adjusting them to £1 at the formation period's outset.\n",
    "\n",
    "$$ Price_{normalized} = P_{time-t} / P_{initial} $$\n",
    "\n",
    "*Reference code: distance_approach.py > def normalizing(data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b465314-a0a9-4b08-81a4-35f38d9dfee7",
   "metadata": {},
   "source": [
    "### 2. Finding pairs with SSD\n",
    "\n",
    "In this method, the spread is calculated by contrasting the normalized cumulative return ($CR$) of each stock pair combination during the 12-month formation period. The spread at time $t$ is derived using an equation. \n",
    "\n",
    "*Reference code: distance_approach.py > def ssd(col1, col2)*\n",
    "\n",
    "Subsequently, the sum of squared differences (SSD) or Euclidean distance between two cumulative return series, $CR_{1}$ and $CR_{2}$, is computed using another equation.\n",
    "\n",
    "$$SSD=\\sqrt{\\sum ^{T}_{t=1}\\left(CR_{1,t}-CR_{2,t}\\right) ^{2}}$$\n",
    "\n",
    "*Reference code: distance_approach.py > def ssd_matrix(dta)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3633c-aa83-4b4e-a09b-295d5750a943",
   "metadata": {},
   "source": [
    "### 3. Selection criteria - historical standard deviation\n",
    "\n",
    "Afterward, the **$n$ pairs with the smallest SSD** are chosen for trading in the subsequent 6-month trading period.\n",
    "\n",
    "In the test, selected n=5 for simplicity.\n",
    "\n",
    "*Reference code: distance_approach.py >*\n",
    "- *def forming_pairs(date1, date2, df),*\n",
    "- *def pair_tickers(coeff_matrix, coeff_list, x)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82f78d-cb49-42f1-9dec-d039aa1e6b2a",
   "metadata": {},
   "source": [
    "### 4. Calculating historical volatility\n",
    "\n",
    "Moreover, the standard deviation of the spread calculated during the formation period acts as a trading criterion.\n",
    "\n",
    "*Reference code: distance_approach.py > def standard_deviation(col1,col2)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a9b07-68cf-478e-858f-edc4adbc0cda",
   "metadata": {},
   "source": [
    "## Trading Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd61204-3a32-4aa1-980d-c93836225a48",
   "metadata": {},
   "source": [
    "### 1. Normalization of the input data in trading period\n",
    "\n",
    "The normalized price denotes the cumulative return sequence, computed by dividing the closing prices by the closing price on the initial day of the trading period, then adjusting them to £1 at the trading period's outset.\n",
    "\n",
    "*Reference code: distance_approach.py > def normalizing(data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869f79e-fadd-42f9-9563-3e96e83a58a6",
   "metadata": {},
   "source": [
    "### 2. Trading Signal\n",
    "\n",
    "- Positions are initiated when the spread deviates by at least 2$\\sigma$  established during the formation period.\n",
    "- This entails purchasing the undervalued stock and selling the overvalued one.\n",
    "- Upon the spread converging to 0, positions are terminated and the process repeats.\n",
    "- Maintaining a consistent 2-$\\sigma$ threshold allows for initiating positions with smaller divergences, potentially resulting in losses upon convergence for less volatile spreads.\n",
    "- Regardless, any open positions at the end of the trading period are closed, irrespective of whether the mispricing persists.\n",
    "\n",
    "*Reference code: distance_approach.py > def trading_df(pair1, pair2, date1, date2, date3, date4, df)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed6a40-9f08-4cec-8271-48676ac39889",
   "metadata": {},
   "source": [
    "### 3. Implement Trading Strategy\n",
    "\n",
    "Execute the strategy based on the trading signals produced for the stock pair and calculate the profit accrued over the 6-month period.\n",
    "\n",
    "*Reference code: distance_approach.py > def trading(dta, capital)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911869e-96eb-4803-bd90-8b87ec53d129",
   "metadata": {},
   "source": [
    "## 3. Cointegration Approach <a class=\"anchor\" id=\"cointegration-approach\"></a>\n",
    "\n",
    "\"Cointegration\" denotes a situation in which two time series, $X_{1}$ and $X_{2}$, display a stable linear combination. It helps pinpoint deviations from long-term equilibrium. Engle and Granger (1997) propose a two-step method for cointegration testing. \n",
    "\n",
    "1. Estimate the individual unit root tests (such as Augmented Dickey-Fuller tests) for each of the variables (spread) in the time series.\n",
    "2. Regress one variable on the other (or a linear combination of the variables) and obtain the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a1048c-803a-48c0-8e73-2d436d28bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coint_Trading(date1, date2, date3, date4, n, df, capital=10000): # date1, date2 formation period, date3, date4 trading period, x stocks\n",
    "    # formation period\n",
    "    pairs = coint_pairs(date1, date2, n, df)\n",
    "    print(pairs)\n",
    "    # trading period\n",
    "    returns = []\n",
    "    for i in pairs:\n",
    "        pair1 = i[0]\n",
    "        pair2 = i[1]\n",
    "        std, mean = spread_stat(date1, date2, pair1, pair2, df)\n",
    "        df1, df2 = signal(date3, date4, std, mean, pair1, pair2, df)\n",
    "        pair1_r = trading(df1, capital)\n",
    "        pair2_r = trading(df2, capital)\n",
    "        pair_return = pair_profit(pair1_r, pair2_r)\n",
    "        returns.append(pair_return)\n",
    "    return(returns)\n",
    "    return(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f766e-8646-4bad-97c0-d3c253322beb",
   "metadata": {},
   "source": [
    "## Formation Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28733e64-e6cb-4d7f-9aea-37aa4e32df57",
   "metadata": {},
   "source": [
    "### 1. Pair Selection ranked on SSD\n",
    "\n",
    "In the first stage, pairs are ranked based on the Sum of Squared Differences (SSD) of their normalized prices during the formation period. This involves ranking all possible pairs to identify those with the lowest SSD, highlighting pairs showing the least divergence in price movements.\n",
    "\n",
    "*Reference code: cointegration_approach.py > def forming_pairs(date1, date2, df), def pair_tickers(coeff_matrix, coeff_list)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e41d4-c320-4d47-a645-d98f03f4bb29",
   "metadata": {},
   "source": [
    "### 2. Find Cointegrated Pairs\n",
    "\n",
    "In the second stage, selected pairs undergo further evaluation of cointegration, closely following the **Engle and Granger two-step approach**. Cumulative return analysis over the formation period determines the presence of a stable, long-term relationship between pairs, identifying those with significant cointegration.\n",
    "\n",
    "The code sets the critical value as 0.05 and compares it to the p-value to evaluate the evidence of cointegration between the series.\n",
    "\n",
    "*Reference code: cointegration_approach.py > def find_cointegrated_pairs(date1, date2, df)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef515b-0426-4c4f-8106-a63b01f525a8",
   "metadata": {},
   "source": [
    "### 3. Selection criteria - cointegration and historical standard deviation\n",
    "\n",
    "Cointegrated pairs are identified through the estimation of their cointegration coefficient, known as $\\beta$, which serves as a hedge ratio. This ratio is utilized in constructing the pairs portfolio\n",
    "\n",
    "Pairs lacking cointegration are excluded, while cointegrated pairs undergo $\\beta$ estimation until $n$ pairs with minimal SSDs are identified for trading. \n",
    "\n",
    "Spreads are constructed and the series represents the scaled price difference between two stocks, as expressed by the equation:\n",
    "\n",
    "$$Spread_{t} = X_{2,t}-\\beta X_{1,t}$$\n",
    "\n",
    "The equation above can be interpreted as purchasing one share of stock 2 and selling $\\beta$ shares of stock 1 at time $t-1$, with the profit calculation taking place at time $t$ upon closing the position.\n",
    "\n",
    "The mean ($\\mu_{e}$) and standard deviation ($\\sigma_{e}$) of spread is used to compute for position triggers from equation:\n",
    "\n",
    "$$Spread_{normalized}=\\dfrac{Spread-\\mu_{e}}{\\sigma _{e}}$$\n",
    "\n",
    "*Reference code: cointegration_approach.py > def coint_pairs(date1, date2, x, df), def spread_stat(date1, date2, pair1, pair2, df)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50adb2d-0d40-4fc2-8378-f94a895c014c",
   "metadata": {},
   "source": [
    "## Trading Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6dd3cd-96b9-4e74-babe-abd1a7c7efef",
   "metadata": {},
   "source": [
    "The trading strategy, akin to the distance approach, initiates long and short positions upon a 2-standard deviation ($\\sigma$) deviation in the normalized spread. \n",
    "\n",
    "The cointegration coefficient, denoted as $\\beta$, can also be employed in equation:\n",
    "\n",
    "$$ Profit = (X_{2,t}-\\beta X_{1,t})-(X_{2,t-1}-\\beta X_{1,t-1})\\\\ =Spread_{t}-Spread_{t-1}$$\n",
    "\n",
    "Unlike the distance approach, long and short positions differ in value. \n",
    "- When the spread falls below -2$\\sigma$, £1 of stock 2 is bought and £$\\beta$ of stock 1 is sold;\n",
    "- if the spread exceeds +2$\\sigma$, $\\dfrac{£1}{\\beta}$ of stock 2 is sold and £1 is invested in stock 1.\n",
    "\n",
    "Positions are reversed when the spread returns to 0, indicating the pair's equilibrium. This cycle repeats throughout the trading period.\n",
    "\n",
    "*Reference code: cointegration_approach.py > def signal(date1, date2, std, mean, pair1, pair2, df), def trading(dta, capital)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc4811-88d4-4063-a4ff-de62acdcac08",
   "metadata": {},
   "source": [
    "## 4. Copula Approach <a class=\"anchor\" id=\"copula-approach\"></a>\n",
    "\n",
    "\n",
    "A copula is like a connector between individual distribution functions and their combined distribution function, especially useful in time series analysis. It helps us understand how different distributions relate to each other over time. Think of it as a joint distribution function where each variable's distribution is uniform. \n",
    "\n",
    "In below copula function, ($U_{1}, U_{2},\\ldots, U_{n}$) covers all possible quantile values, while ($u_{1},u_{2},\\ldots, u_{n}$) refers to specific observations from a uniform distribution.\n",
    "\n",
    "$$ C\\left( u_{1},u_{2},\\ldots ,u_n\\right)=P(U_{1}\\leq u_{1},U_{2}\\leq u_{2},\\ldots,U_{n}\\leq u_{n})$$\n",
    "\n",
    "The conditional distribution function can be obtained by taking the partial derivative of the copula function, as equations:\n",
    "\n",
    "$$h_{1}\\left(u_{1}|u_{2}\\right)=P\\left(U_{1}\\leq u_{1}|U_{2}=u_{2}\\right)=\\dfrac{\\partial C\\left(u_{1},u_{2}\\right) }{\\partial u_{2}}\\\\$$\n",
    "$$h_{2}\\left(u_{2}|u_{1}\\right)=P\\left(U_{2}\\leq u_{2}|U_{1}=u_{1}\\right)=\\dfrac{\\partial C\\left(u_{1},u_{2}\\right) }{\\partial u_{1}}$$\n",
    "\n",
    "\n",
    "Using functions $h_{1}$ and $h_{2}$ allows for estimating the likelihood of one random variable being smaller than a given value while the other assumes a fixed value. In pairs trading, these functions predict whether one stock in a pair will rise or fall relative to its price, based on the other stock's price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223522a-1110-4a08-b81b-09f8041656f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copula_approach(stocks, df_data, date1, date2, date3, date4, x, y): # formation period: date1, date2. trading period: date3, date4\n",
    "    # prepare data set\n",
    "    df_data_form, df_data_trade = train_test_split(\n",
    "        df_data, date1, date2, date3, date4)\n",
    "    df_data_form.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_data_form.dropna(inplace=True)\n",
    "    df_data_trade.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_data_trade.dropna(inplace=True)\n",
    "    # formation period\n",
    "    df_tau_results = calc_tau(stocks, df_data_form).dropna()\n",
    "    pairs_selected = select_pairs(df_data_form, df_tau_results)[:x]\n",
    "    \n",
    "    df_copula_results = copula_formation(\n",
    "        df_data_form, df_tau_results.loc[pairs_selected], pairs_selected)\n",
    "    # trading period\n",
    "    threshold = y\n",
    "    trade_results = {}\n",
    "    for pair in pairs_selected:\n",
    "        stock_1, stock_2 = parse_pair(pair)\n",
    "        df_calculations, df_positions, df_returns = copula_trading(\n",
    "            df_data, df_data_form, df_data_trade, df_copula_results, pair, threshold)\n",
    "\n",
    "        trade_results[pair] = {'calculations': df_calculations,\n",
    "                               'positions': df_positions,\n",
    "                               'returns': df_returns,\n",
    "                               'metrics': metrics(df_returns.sum(axis=1))}\n",
    "    print(df_returns)\n",
    "    pairs_returns = []\n",
    "    for pair in pairs_selected:\n",
    "        df_pair_return = trade_results[pair]['returns'].astype(float) #trade_results\n",
    "        pairs_returns.append(df_pair_return.sum(axis=1))\n",
    "\n",
    "    return(pairs_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc7baf-0bf5-4465-8d8a-9c2c32330a8d",
   "metadata": {},
   "source": [
    "## Formation Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbb370-55cf-4e5b-aa65-3e783bc1b03f",
   "metadata": {},
   "source": [
    "### 1. Select Stock Pairs with Kendall's Tau $\\tau$:\n",
    "\n",
    "While parametric measures like SSD and cointegration are often used, the copula approach favors non-parametric tests such as Kendall's $\\tau$ for assessing pair correlation. In this project, cumulative returns are calculated alongside Kendall's $\\tau$ for each pair of stocks.\n",
    "\n",
    "Higher Kendall's $\\tau$ values indicate stronger pair movements, aligning well with copula analysis principles rooted in concordance. The top $n$ pairs are selected based on Kendall's $\\tau$.\n",
    "\n",
    "*Reference code: copula_approach.py > def calc_tau(stocks: list, df_data: pd.DataFrame) -> pd.DataFrame, def select_pairs(df_data_form: pd.DataFrame, df_tau_results: pd.DataFrame) -> list*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6806695a-b3d4-4f77-90ec-5c6896de9159",
   "metadata": {},
   "source": [
    "### 2. Fitting Copula Functions to Selected Pairs:\n",
    "\n",
    "The top $n$ pairs undergo copula fitting in two steps. \n",
    "\n",
    "1. Firstly, daily returns from the formation period are fitted to marginal distributions for each pair.\n",
    "2. Then, the copula that best fits the uniform marginals, using estimated parameters, is selected and parameterized.\n",
    "\n",
    "\n",
    "Following the methodology of Liew and Wu (2013) and Xie et. al. (2014), commonly used copulas in financial asset analysis like Gaussian, Student-t, Gumbel, Clayton, and Frank are examined. \n",
    "\n",
    "The optimal copula accurately represents interdependence patterns among stocks, determined by maximizing log-likelihood and computing the Akaike Information Criterion (AIC) for performance evaluation. The copula with the highest AIC is chosen.\n",
    "\n",
    "*Reference code: copula_approach.py > def fit_copula(df_data: pd.DataFrame, pairs_selected: list) -> pd.DataFrame, def copula_formation(df_data_form:pd.DataFrame, df_tau_results:pd.DataFrame, pairs_selected:list)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3943cb-e0f9-4005-a97d-2af4a24e1350",
   "metadata": {},
   "source": [
    "## Trading Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61c703-6f4d-4196-9a5e-78ab74032757",
   "metadata": {},
   "source": [
    "### 1. Calculating Conditional Probabilities of Pairs\n",
    "\n",
    "During the trading period, conditional probabilities are computed using the daily returns of two stocks in a pair, as detailed in above $h_{1}$ and $h_{2}$ functions.\n",
    "\n",
    "A value of 0.5 for $h_{1}$ or $h_{2}$ denotes a 50% probability that the price of stock 1 ($U_{1}$) or stock 2 ($U_{2}$) will be lower than its current observed value, based on the present price of the other stock. \n",
    "\n",
    "Values exceeding 0.5 indicate a higher likelihood of the stock price decreasing relative to its current value, while values below 0.5 suggest a greater probability of the stock price increasing.\n",
    "\n",
    "*Reference code: copula_approach.py > def copula_trading(df_data, df_data_form:pd.DataFrame, df_data_trade:pd.DataFrame, df_copula_results:pd.DataFrame, pair:str, threshold:float)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4881cb-fa14-4eb7-b9ca-130630298649",
   "metadata": {},
   "source": [
    "### 2. Establishing Cumulative Mispricing Indices (CMPI)\n",
    "\n",
    "Following the approach of Xie et al. (2014), two indices defining mispricing are formulated using below equations.\n",
    "\n",
    "$$m_{1,t}=h_{1}\\left(u_{1}|u_{2}\\right)-0.5=P\\left(U_{1}\\leq u_{1}|U_{2}=u_{2}\\right)-0.5\\\\$$\n",
    "$$m_{2,t}=h_{2}\\left(u_{2}|u_{1}\\right)-0.5=P\\left(U_{2}\\leq u_{2}|U_{1}=u_{1}\\right)-0.5$$\n",
    "\n",
    "On a daily basis, the cumulative mispriced indices (CMPI) $M_{1}$ and $M_{2}$ are calculated using below equations, with an initial value of zero at the beginning of the trading period.\n",
    "\n",
    "$$M_{1,t}=M_{1,t-1}+m_{1,t}\\\\$$\n",
    "$$M_{2,t}=M_{2,t-1}+m_{2,t}$$\n",
    "\n",
    "Positive $M_{1}$ and negative $M_{2}$ values suggest that stock 1 is overvalued compared to stock 2, whereas negative $M_{1}$ and positive $M_{2}$ values indicate the opposite.\n",
    "\n",
    "*Reference code: copula_approach.py > def copula_trading(df_data, df_data_form:pd.DataFrame, df_data_trade:pd.DataFrame, df_copula_results:pd.DataFrame, pair:str, threshold:float)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddec6bd-089b-4384-abf5-6165026dc789",
   "metadata": {},
   "source": [
    "### 3. Implementing Trading Strategy\n",
    "\n",
    "A long-short position is initiated when one CMPI exceeds 0.5 while the other falls below -0.5 simultaneously. Positions are reversed when both CMPI return to zero. \n",
    "\n",
    "Continuous monitoring for potential trades is then conducted for the remainder of the trading period.\n",
    "\n",
    "*Reference code: copula_approach.py > def copula_trading(df_data, df_data_form:pd.DataFrame, df_data_trade:pd.DataFrame, df_copula_results:pd.DataFrame, pair:str, threshold:float)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae9b37-d90f-40e2-8ff1-e104319f796f",
   "metadata": {},
   "source": [
    "## 5. Conclusion <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "Based on backtesting results, the distance approach yields a -80% cumulative return with an 81% max drawdown. In contrast, cointegration and copula approaches achieve positive returns of 42% and 41%, respectively, with lower drawdowns.\n",
    "\n",
    "Among the three strategies, copula demonstrates the highest Sharpe ratio (12.06), indicating superior risk-adjusted returns. Despite achieving a similar cumulative return to cointegration, copula exhibits significantly lower volatility during the trading period, suggesting better risk management and potential for stable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5fe3ca-0d6f-489e-9ec8-768b16d11ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start Period</th>\n",
       "      <th>End Period</th>\n",
       "      <th>Risk-Free Rate</th>\n",
       "      <th>Time in Market</th>\n",
       "      <th>Cumulative Return</th>\n",
       "      <th>CAGR﹪</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>Prob. Sharpe Ratio</th>\n",
       "      <th>Sortino</th>\n",
       "      <th>...</th>\n",
       "      <th>1Y</th>\n",
       "      <th>3Y (ann.)</th>\n",
       "      <th>5Y (ann.)</th>\n",
       "      <th>10Y (ann.)</th>\n",
       "      <th>All-time (ann.)</th>\n",
       "      <th>Avg. Drawdown</th>\n",
       "      <th>Avg. Drawdown Days</th>\n",
       "      <th>Recovery Factor</th>\n",
       "      <th>Ulcer Index</th>\n",
       "      <th>Serenity Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Distance Approach</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>-80.39%</td>\n",
       "      <td>-67.53%</td>\n",
       "      <td>-13.42</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>-10.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.39%</td>\n",
       "      <td>-67.53%</td>\n",
       "      <td>-67.53%</td>\n",
       "      <td>-67.53%</td>\n",
       "      <td>-67.53%</td>\n",
       "      <td>-81.41%</td>\n",
       "      <td>338</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cointegration Approach</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>41.83%</td>\n",
       "      <td>27.29%</td>\n",
       "      <td>5.21</td>\n",
       "      <td>83.6%</td>\n",
       "      <td>9.21</td>\n",
       "      <td>...</td>\n",
       "      <td>41.83%</td>\n",
       "      <td>27.29%</td>\n",
       "      <td>27.29%</td>\n",
       "      <td>27.29%</td>\n",
       "      <td>27.29%</td>\n",
       "      <td>-12.45%</td>\n",
       "      <td>92</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Copula Approach</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>40.79%</td>\n",
       "      <td>26.64%</td>\n",
       "      <td>12.06</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>72.05</td>\n",
       "      <td>...</td>\n",
       "      <td>40.79%</td>\n",
       "      <td>26.64%</td>\n",
       "      <td>26.64%</td>\n",
       "      <td>26.64%</td>\n",
       "      <td>26.64%</td>\n",
       "      <td>-1.59%</td>\n",
       "      <td>18</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>106.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0 Start Period  End Period Risk-Free Rate  \\\n",
       "0       Distance Approach   2021-01-04  2022-01-04           2.0%   \n",
       "1  Cointegration Approach   2021-01-04  2022-01-04           2.0%   \n",
       "2         Copula Approach   2021-01-04  2022-01-04           2.0%   \n",
       "\n",
       "  Time in Market Cumulative Return    CAGR﹪  Sharpe Prob. Sharpe Ratio  \\\n",
       "0         100.0%           -80.39%  -67.53%  -13.42               0.0%   \n",
       "1         100.0%            41.83%   27.29%    5.21              83.6%   \n",
       "2         100.0%            40.79%   26.64%   12.06             100.0%   \n",
       "\n",
       "   Sortino  ...       1Y  3Y (ann.) 5Y (ann.)  10Y (ann.)  All-time (ann.)  \\\n",
       "0   -10.51  ...  -80.39%    -67.53%   -67.53%     -67.53%          -67.53%   \n",
       "1     9.21  ...   41.83%     27.29%    27.29%      27.29%           27.29%   \n",
       "2    72.05  ...   40.79%     26.64%    26.64%      26.64%           26.64%   \n",
       "\n",
       "   Avg. Drawdown  Avg. Drawdown Days  Recovery Factor  Ulcer Index  \\\n",
       "0        -81.41%                 338             1.73         0.61   \n",
       "1        -12.45%                  92             1.74         0.11   \n",
       "2         -1.59%                  18            14.06         0.01   \n",
       "\n",
       "   Serenity Index  \n",
       "0           -0.29  \n",
       "1            1.51  \n",
       "2          106.88  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "overall_performance = pd.read_excel('test/profitability_3_approaches.xlsx')\n",
    "overall_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0790d5-e64c-489a-91b4-f18298b78649",
   "metadata": {},
   "source": [
    "## 6. Reference <a class=\"anchor\" id=\"reference\"></a>\n",
    "\n",
    "[Engle and Granger, 1987] Engle, R. F. and Granger, C.W. J. (1987). Co-Integration and Error Correction: Representation, Estimation, and Testing. Econometrica, 55(2):251–276.\n",
    "\n",
    "[Gatev et al., 2006] Gatev, E., Goetzmann, W. N., and Rouwenhorst, K. G. (2006). Pairs trading: Performance of a relative-value arbitrage rule. Review of Financial Studies, 19(3):797–827.\n",
    "\n",
    "[Liew and Wu, 2013] Liew, R. Q. andWu, Y. (2013). Pairs Trading: A Copula Approach. Journal of Derivatives and Hedge Funds, 19(1):12–30.\n",
    "\n",
    "[Xie et al., 2014] Xie, W., Liew, R. Q., Wu, Y., and Zou, X. (2014). Pairs Trading with Copulas. Journal of Derivatives & Hedge Funds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
